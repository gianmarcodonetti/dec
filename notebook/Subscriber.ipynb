{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import redis\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from dec import subscriber, publisher, constants as C, statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subscriber started. Establishing connection to REDIS...\n",
      "Subscribed to channel 'events'.\n",
      "Pulling a new message...\n",
      "No message found in the queue.\n",
      "Pulling a new message...\n",
      "No message found in the queue.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "No statistics valid found.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "A new message has been pulled.\n",
      "Computing statistics related to the new data...\n",
      "Reading old statistics...\n",
      "Last statistics parsed.\n",
      "Updating all the statistics...\n",
      "Writing updated statistics...\n",
      "Full step completed.\n",
      "Pulling a new message...\n",
      "No message found in the queue.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2c2634a48ea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msubscriber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\g.donetti\\seafile\\my library\\work\\data_engineer_challenge\\repository\\dec\\dec\\subscriber.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No message found in the queue.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "subscriber.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = redis.StrictRedis(host='localhost', port=6379, db=0)\n",
    "pubsub = rc.pubsub()\n",
    "pubsub.subscribe(['events'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty message\n",
    "message = pubsub.get_message()\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = pubsub.get_message()\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_to_process = eval(message['data'])\n",
    "\n",
    "events_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "We would like to see a bunch of statistics saved and updated in Redis\n",
    "1. total sum of viewable_time per publisher (viewable_time_sum_per_publisher)\n",
    "2. the top 10 publishers by events count (top_n_publisher_by_count)\n",
    "3. the number of uniques clips per publisher (unique_clips_count_per_publisher)\n",
    "4. total sum of clips per country viewed by day and by night (clips_count_per_country_day_night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1\n",
    "statistics.viewable_time_sum_per_publisher(events_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "statistics.top_n_publisher_by_count(events_to_process, n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "statistics.unique_clips_count_per_publisher(events_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "statistics.clips_count_per_country_day_night(events_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single step job\n",
    "\n",
    "These will be the main steps of a single run:\n",
    "\n",
    "1. Get a new message from the publisher\n",
    "2. If the message is not empty, continue, else reloop\n",
    "3. Compute the above statistics for the new events\n",
    "4. Read the previous computed statistics\n",
    "5. Update all the statistics\n",
    "6. Write the updated statistics\n",
    "\n",
    "This will be the format of the persisted statistics:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_persisted = {\n",
    "    'statistics': {\n",
    "        'viewable_time_sum_per_publisher': {\n",
    "            '<PUBID>': '<actual_total_sum>',\n",
    "            # ...\n",
    "        },\n",
    "        'top_n_publisher_by_count': {\n",
    "            'data': '<actual_data>',\n",
    "            'publishers': '<PUBID_1>,...,<PUBID_i>,...,<PUBID_N>',\n",
    "        },\n",
    "        'unique_clips_count_per_publisher': {\n",
    "            'data': {\n",
    "                '<PUBID>': '<CLIP_1>,...,<CLIP_N>',\n",
    "                # ...\n",
    "            },\n",
    "            'counts': {\n",
    "                '<PUBID>': 'N',\n",
    "                # ...\n",
    "            },\n",
    "        },\n",
    "        'clips_count_per_country_day_night': {\n",
    "            '<COUNTRY_1>': {\n",
    "                'day': 'X',\n",
    "                'night': 'Y'\n",
    "            },\n",
    "            # ...\n",
    "        }\n",
    "    },\n",
    "    'last_update_timestamp': '<last_update_timestamp_value>'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.delete('statistics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stats_str = rc.get('statistics')\n",
    "\n",
    "try:\n",
    "    last_stats = eval(last_stats_str)\n",
    "except TypeError:\n",
    "    last_stats = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewable_time = statistics.viewable_time_sum_per_publisher(events_to_process)\n",
    "top_pub = statistics.top_n_publisher_by_count(events_to_process, n=10)\n",
    "unique_clips_count = statistics.unique_clips_count_per_publisher(events_to_process)\n",
    "clips_count = statistics.clips_count_per_country_day_night(events_to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = last_stats.get('statistics', {})\n",
    "\n",
    "# 1. Viewable time\n",
    "updated_viewable_time = subscriber.update_viewable_time(stats, viewable_time)\n",
    "updated_viewable_time_list = list(updated_viewable_time.T.to_dict().values())\n",
    "\n",
    "# 2. Top pub\n",
    "updated_top_pub = subscriber.update_top_pub(stats, top_pub)\n",
    "updated_top_pub_list = list(updated_top_pub.T.to_dict().values())\n",
    "\n",
    "# 3. Unique clips count\n",
    "updated_unique_clips_count = subscriber.update_unique_clips_count(stats, unique_clips_count)\n",
    "updated_unique_clips_count_list = list(updated_unique_clips_count.T.to_dict().values())\n",
    "\n",
    "# 4. Clips count\n",
    "updated_clips_count = subscriber.update_clips_count(stats, clips_count)\n",
    "updated_clips_count_list = list(updated_clips_count.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_viewable_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_top_pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(updated_top_pub[C.PUBLISHER_ID].values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_unique_clips_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_clips_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_stats = {\n",
    "    'statistics': {\n",
    "        'viewable_time_sum_per_publisher': updated_viewable_time_list,\n",
    "        'top_n_publisher_by_count': {\n",
    "            'data': updated_top_pub_list,\n",
    "            'publishers': ','.join(updated_top_pub[C.PUBLISHER_ID].values[:10]),\n",
    "        },\n",
    "        'unique_clips_count_per_publisher': {\n",
    "            'data': updated_unique_clips_count_list,\n",
    "        },\n",
    "        'clips_count_per_country_day_night': updated_clips_count_list\n",
    "    },\n",
    "    'last_update_timestamp': datetime.now().timestamp()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_stats = subscriber.update_stats(last_stats, viewable_time, top_pub, unique_clips_count, clips_count)\n",
    "\n",
    "updated_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.set('statistics', updated_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = pubsub.get_message()\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    events_to_process = eval(message['data'])\n",
    "    subscriber.single_step_run(events_to_process)\n",
    "except TypeError:\n",
    "    # No data read\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update viewable_time\n",
    "stats = last_stats.get('statistics', {})\n",
    "\n",
    "last_viewable_time = stats.get('viewable_time_sum_per_publisher', pd.DataFrame(columns=[C.PUBLISHER_ID, C.VIEWABLE_TIME]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_viewable_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = (pd.merge(last_viewable_time, pd.DataFrame(viewable_time), how='outer', on=[C.PUBLISHER_ID])\n",
    "              .set_index([C.PUBLISHER_ID])\n",
    "              .sum(axis=1)\n",
    "              .reset_index()\n",
    "              .rename(columns={0: C.VIEWABLE_TIME})\n",
    "             )\n",
    "\n",
    "list(updated_df.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update top_pub\n",
    "stats = last_stats.get('statistics', {})\n",
    "\n",
    "last_top_pub_dict = stats.get('top_pub', {})\n",
    "last_top_pub = last_top_pub_dict.get('data', pd.DataFrame(columns=[C.PUBLISHER_ID, 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = (pd.merge(last_top_pub, pd.DataFrame(top_pub), how='outer', on=[C.PUBLISHER_ID])\n",
    "              .set_index([C.PUBLISHER_ID])\n",
    "              .sum(axis=1)\n",
    "              .reset_index()\n",
    "              .rename(columns={0: 'count'})\n",
    "             )\n",
    "\n",
    "list(updated_df.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update top_pub\n",
    "stats = last_stats.get('statistics', {})\n",
    "\n",
    "last_unique_clips_count_dict = stats.get('unique_clips_count_per_publisher', {})\n",
    "\n",
    "last_unique_clips_count = last_unique_clips_count_dict.get('data', pd.DataFrame(columns=[C.PUBLISHER_ID, 'clips']))\n",
    "last_unique_clips_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_clips_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_sum(lis):\n",
    "    head = lis[0]\n",
    "    if isinstance(head, set) is False:\n",
    "        head = set()\n",
    "    if len(lis) > 1:\n",
    "        return head.union(special_sum(lis[1:]))\n",
    "    else:\n",
    "        return head\n",
    "\n",
    "updated_df = (pd.merge(last_unique_clips_count, pd.DataFrame(unique_clips_count), how='outer', on=[C.PUBLISHER_ID])\n",
    "              .set_index([C.PUBLISHER_ID])\n",
    "              .aggregate(special_sum, axis=1)\n",
    "              .reset_index()\n",
    "              .rename(columns={0: 'unique_clips'})\n",
    "             )\n",
    "\n",
    "list(updated_df.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update clips_count\n",
    "stats = last_stats.get('statistics', {})\n",
    "\n",
    "data_str = stats.get('clips_count_per_country_day_night', None)\n",
    "last_clips_count = pd.DataFrame(data_str) if data_str else pd.DataFrame(columns=[C.COUNTRY, 'daynight', 'count'])\n",
    "\n",
    "last_clips_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df = (pd.merge(last_clips_count, pd.DataFrame(clips_count), how='outer', on=[C.COUNTRY, 'daynight'])\n",
    "              .set_index([C.COUNTRY, 'daynight'])\n",
    "              .sum(axis=1)\n",
    "              .reset_index()\n",
    "              .rename(columns={0: 'count'})\n",
    "             )\n",
    "\n",
    "list(updated_df.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
